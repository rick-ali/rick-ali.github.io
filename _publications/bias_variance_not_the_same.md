---
title: "Bias/Variance is not the same as Approximation/Estimation"
collection: publications
category: manuscripts
permalink: /publication/bias-variance-is-not-the-same-as-approximation-estimation
excerpt: 'We establish a formal connection between the two seminal decompositions using ideas from statistical learning theory and information geometry.'
date: 2024-03-05
venue: 'TMLR'
paperurl: 'https://openreview.net/forum?id=4TnFbv16hK'
citation: 'Gavin Brown, Riccardo Ali'
---

We study the relation between two classical results: the bias-variance decomposition, and the approximation-estimation decomposition. Both are important conceptual tools in Machine Learning, helping us describe the nature of model fitting. It is commonly stated that they are “closely related”, or “similar in spirit”. However, sometimes it is said they are equivalent. In fact they are different, but have subtle connections cutting across learning theory, classical statistics, and information geometry, that (very surprisingly) have not been previously observed. We present several results for losses expressible as Bregman divergences: a broad family with a known bias-variance decomposition. Discussion and future directions are presented for more general losses, including the 0/1 classification loss.

